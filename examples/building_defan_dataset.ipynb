{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13191,"status":"ok","timestamp":1725834127886,"user":{"displayName":"Juan Vazquez","userId":"09405199166243788738"},"user_tz":-120},"id":"yuFzMkqIz0Xt","outputId":"a6d9f94e-ef3f-4115-9826-6f33dbf02ec8"},"outputs":[],"source":["!pip install uv\n","!pip install python-dotenv\n","!pip install openai\n","!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":670,"status":"ok","timestamp":1725834128551,"user":{"displayName":"Juan Vazquez","userId":"09405199166243788738"},"user_tz":-120},"id":"lUxMeh2EwkBM","outputId":"e8083e1d-d786-43be-aec6-419085a3ef0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'PIZZA'...\n","remote: Enumerating objects: 1031, done.\u001b[K\n","remote: Counting objects: 100% (556/556), done.\u001b[K\n","remote: Compressing objects: 100% (260/260), done.\u001b[K\n","remote: Total 1031 (delta 388), reused 417 (delta 295), pack-reused 475 (from 1)\u001b[K\n","Receiving objects: 100% (1031/1031), 3.91 MiB | 11.77 MiB/s, done.\n","Resolving deltas: 100% (688/688), done.\n"]}],"source":["!git clone https://github.com/leap-laboratories/PIZZA.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1774,"status":"ok","timestamp":1725834130319,"user":{"displayName":"Juan Vazquez","userId":"09405199166243788738"},"user_tz":-120},"id":"v63GpMclwlTE","outputId":"d61e589a-06de-4ff4-a392-691c8ff7229d"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/PIZZA/PIZZA\n","Using Python 3.10.12 interpreter at: \u001b[36m/usr/bin/python3\u001b[39m\n","Creating virtualenv at: \u001b[36m.venv\u001b[39m\n","Activate with: \u001b[32msource .venv/bin/activate\u001b[39m\n","\u001b[2K\u001b[2mResolved \u001b[1m68 packages\u001b[0m \u001b[2min 684ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mInstalled \u001b[1m68 packages\u001b[0m \u001b[2min 454ms\u001b[0m\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.4.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2024.2.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.3.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.2.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mdistro\u001b[0m\u001b[2m==1.9.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mexceptiongroup\u001b[0m\u001b[2m==1.2.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.14.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.52.4\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2024.5.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.14.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.5\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.27.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.23.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.7\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.4\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.4.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.5\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==3.0.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==2.1.5\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.9.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.3\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.1.3.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.1.105\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.1.105\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.1.105\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==8.9.2.26\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.0.2.54\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.2.106\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.4.5.107\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.1.0.106\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.19.3\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.6.68\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.1.105\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.19.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==24.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.2.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==10.3.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.7.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.18.3\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.18.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.1.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.0.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2024.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2024.5.15\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.3\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==13.7.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.4.3\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.4.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.16.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.12.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.5.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.19.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.2.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.66.4\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.43.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==2.2.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.12.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2024.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.2.1\u001b[0m\n"]}],"source":["%cd PIZZA\n","!uv venv\n","!source .venv/bin/activate\n","!uv pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1725834130320,"user":{"displayName":"Juan Vazquez","userId":"09405199166243788738"},"user_tz":-120},"id":"Yw5yRop0wonL","outputId":"eb81b567-c92a-403b-c1ad-97696b370540"},"outputs":[{"name":"stdout","output_type":"stream","text":["The dotenv extension is already loaded. To reload it, use:\n","  %reload_ext dotenv\n"]}],"source":["!echo \"OPENAI_API_KEY=your_api_key\" > .env\n","%load_ext dotenv\n","%dotenv"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3957,"status":"ok","timestamp":1725835329258,"user":{"displayName":"Juan Vazquez","userId":"09405199166243788738"},"user_tz":-120},"id":"uDMdRy4hgKh2","outputId":"bb4f0c50-8b00-4645-f4ab-1b19fa8fa84d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","import re\n","import time\n","import json\n","import pandas as pd\n","import numpy as np\n","import asyncio\n","\n","import openai\n","from openai import OpenAI\n","\n","from asyncio import Semaphore\n","from tqdm.asyncio import tqdm\n","\n","import warnings\n","warnings.simplefilter(\"ignore\")\n","\n","from attribution.api_attribution import OpenAIAttributor\n","from attribution.experiment_logger import ExperimentLogger\n","from attribution.token_perturbation import (\n","    FixedPerturbationStrategy,\n","    NthNearestPerturbationStrategy,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qOyZptl1B5HJ"},"outputs":[],"source":["dataset_dir = '/path_to_defan_dataset'\n","dataset_fn = '<fn>.csv'\n","\n","df = pd.read_csv(os.path.join(dataset_dir, dataset_fn))\n","\n","results_dir = '/results_dir'\n","\n","os.makedirs(results_dir, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E0uBDj2wE7Na"},"outputs":[],"source":["attributor = OpenAIAttributor(openai_model='gpt-4o-mini') # gpt-3.5-turbo, gpt-4o-mini"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUYzhwXoKbON"},"outputs":[],"source":["PROMPT_TEMPLATE_VERDICT = \"\"\"\n","You are presented with a MODEL_ANSWER and the CORRECT_ANSWER to a question. Evaluate the MODEL_ANSWER using the following steps:\n","\n","Compare the MODEL_ANSWER to the CORRECT_ANSWER for accuracy and correctness.\n","\n","Determine if the MODEL_ANSWER falls into one of these categories:\n","a) Correct: The answer matches the CORRECT_ANSWER in all key aspects, and is accurate and complete. If it is correct, the last line of your RESPONSE should be VERDICT: Correct.\n","b) Refusal: The answer indicates an inability to provide an answer or acknowledges a lack of response, is a refusal, doubt, or expresses uncertainty. If it is a refusal, the last line of your RESPONSE should be VERDICT: Refusal.\n","c) Hallucination: The answer states false information that contradicts the CORRECT_ANSWER. If it is a hallucination, the last line of your RESPONSE should be VERDICT: Hallucination.\n","\n","The last line of your RESPONSE must be VERDICT: $VERDICT (without quotes) where $VERDICT is Correct, Refusal, or Hallucination.\n","\n","MODEL_ANSWER: {Model_answer}\n","\n","CORRECT_ANSWER: {Correct_answer}\n","\n","RESPONSE:\n","\"\"\".strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T6GUNLP7C6Tv"},"outputs":[],"source":["def split_array(arr):\n","    tokens = []\n","    att_values = []\n","\n","    for item in arr:\n","        if '\\n' in str(item):\n","            parts = str(item).split('\\n')\n","            tokens.append(parts[0].strip())\n","            att_values.append(float(parts[1]))\n","        else:\n","            tokens.append(str(item).strip())\n","            att_values.append(None)\n","\n","    return tokens, att_values\n","\n","async def get_total_attribution(prompt):\n","    logger = ExperimentLogger()\n","    try:\n","        await attributor.hierarchical_perturbation(\n","            prompt,\n","            logger=logger,\n","            attribution_strategies=[\"cosine\", \"prob_diff\"],\n","            perturbation_strategy=FixedPerturbationStrategy(replacement_token=\"\"),\n","            max_depth=1,\n","        )\n","\n","        output = logger.df_experiments['original_output'].iloc[-1]\n","\n","        total_att = logger.print_total_attribution(exp_id=-1)\n","\n","        try:\n","            mat_full = logger.get_attribution_matrices(exp_id=-1)\n","        except ValueError as e:\n","            print(f\"Error getting attribution matrices: {str(e)}\")\n","            mat_full = None\n","\n","        tokens, cosine_vals = split_array(total_att.values[0][4:])\n","        _, prob_diff_vals = split_array(total_att.values[1][4:])\n","\n","        return cosine_vals, prob_diff_vals, tokens, output, mat_full\n","    except Exception as e:\n","        print(f\"Error in get_total_attribution: {str(e)}\")\n","        return None, None, None, None, None\n","\n","async def get_hallucination_verdict(output, answer):\n","    system_message = \"You are a helpful assistant.\"\n","    model = \"gpt-4o\"\n","    temperature = 0.7\n","    top_p = 1\n","    max_tokens = 800\n","    message_list = [{\"role\": \"user\", \"content\": PROMPT_TEMPLATE_VERDICT.format(Model_answer=output, Correct_answer=answer)}]\n","    message_list = [{\"role\": \"system\", \"content\": system_message}] + message_list\n","\n","    trial = 0\n","    while True:\n","        try:\n","            response = await asyncio.to_thread(\n","                client.chat.completions.create,\n","                model=model,\n","                messages=message_list,\n","                temperature=temperature,\n","                top_p=top_p,\n","                max_tokens=max_tokens,\n","            )\n","            res = response.choices[0].message.content\n","\n","            ANSWER_PATTERN = r\"(?i)VERDICT\\s*:\\s*(.*?)(?:\\n|$)\"\n","            match = re.search(ANSWER_PATTERN, res)\n","\n","            if match:\n","                verdict = match.group(1).strip()\n","                return res, verdict\n","            else:\n","                print('Formatting is not working or a NEW_PROMPT has not been created.')\n","                return res, None\n","        except Exception as e:\n","            exception_backoff = 2**trial  # exponential back off\n","            print(f\"Exception occurred, will retry {trial} after {exception_backoff} seconds.\", e)\n","            await asyncio.sleep(exception_backoff)\n","            trial += 1\n","            if trial > 5:  # Max 5 retries\n","                print(\"Max retries reached. Skipping this request.\")\n","                return None, None\n","\n","async def process_row(idx, question, answer, max_retries=3):\n","    for attempt in range(max_retries):\n","        try:\n","            cosine_vals, prob_diff_vals, tokens, output, mats_full = await get_total_attribution(question)\n","            _, verdict = await get_hallucination_verdict(output, answer)\n","\n","            if mats_full is not None:\n","                mats_json_data = []\n","                for i, df in enumerate(mats_full):\n","                    mats_json_data.append({\n","                        \"matrix_id\": i,\n","                        \"data\": df.reset_index().to_dict(orient=\"records\")\n","                    })\n","            else:\n","                mats_json_data = None\n","\n","            print(f\">>>>Row {idx}<<<<\")\n","            print(f\"Input: {question}\")\n","            print(f\"Output: {output}\")\n","            print(f\"Correct Answer: {answer}\")\n","            print(f\"Verdict: {verdict}\")\n","            print(f\"Tokens: {tokens}\")\n","            print(f\"Cosine values: {cosine_vals}\")\n","            print(f\"ProbDiff values: {prob_diff_vals}\")\n","            print(f\"Mat full: {mats_json_data}\")\n","\n","            result = {\n","                \"row\": idx,\n","                \"input\": question,\n","                \"output\": output,\n","                \"correct_answer\": answer,\n","                \"verdict\": verdict,\n","                \"tokens\": tokens,\n","                \"cosine_values\": cosine_vals,\n","                \"prob_diff_values\": prob_diff_vals,\n","                \"attributions_full\": mats_json_data\n","            }\n","\n","            with open(os.path.join(results_dir, f\"new_result_{idx}.json\"), 'w') as f:\n","                json.dump(result, f, indent=2)\n","\n","            print(f\"Saved result for row Y{idx+1} to JSON file\")\n","            return\n","\n","        except Exception as e:\n","            print(f\"Error processing row {idx}, attempt {attempt + 1}: {str(e)}\")\n","            if attempt == max_retries - 1:\n","                print(f\"Max retries reached for row {idx}. Saving partial data.\")\n","                result = {\n","                    \"row\": idx,\n","                    \"input\": question,\n","                    \"output\": str(e),\n","                    \"correct_answer\": answer,\n","                    \"verdict\": None,\n","                    \"tokens\": None,\n","                    \"cosine_values\": None,\n","                    \"prob_diff_values\": None,\n","                    \"attributions_full\": None\n","                }\n","                with open(os.path.join(results_dir, f\"new_result_{idx}_error.json\"), 'w') as f:\n","                    json.dump(result, f, indent=2)\n","            else:\n","                await asyncio.sleep(1)\n","\n","async def process_rows(df_array, max_concurrent=50):\n","    semaphore = Semaphore(max_concurrent)\n","    total_rows = len(df_array)\n","\n","    async def worker(idx, question, answer):\n","        async with semaphore:\n","            await process_row(idx, question, answer)\n","\n","    tasks = []\n","    for idx, question, answer, _ in df_array:\n","        task = asyncio.create_task(worker(idx, question, answer))\n","        tasks.append(task)\n","\n","    for task in tqdm.as_completed(tasks, total=total_rows, desc=\"Processing rows\"):\n","        try:\n","            await task\n","        except Exception as e:\n","            print(f\"Unhandled error in task: {str(e)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oce4PNtLu9iP"},"outputs":[],"source":["df_array = df.reset_index().values\n","client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1725843426400,"user":{"displayName":"Juan Vazquez","userId":"09405199166243788738"},"user_tz":-120},"id":"Qn1r2hyB-G_J","outputId":"c45657a7-ea98-4a55-e831-01ab77c3033e"},"outputs":[{"data":{"text/plain":["array([0,\n","       ' Which team won the 1930 FIFA World Cup?(Give me the name only)',\n","       'Uruguay', 'name'], dtype=object)"]},"execution_count":160,"metadata":{},"output_type":"execute_result"}],"source":["df_array[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"JSqvm_aayl8t","outputId":"7e9da0eb-94e6-4eed-b556-c38798e08eac"},"outputs":[],"source":["start_time = time.time()\n","await process_rows(df_array[:1000])\n","end_time = time.time()\n","\n","print(f\"\\nTotal processing time: {end_time - start_time:.2f} seconds\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNXVkRz+mtFKutJYCUiPV/d","machine_shape":"hm","provenance":[{"file_id":"1KFGO0832V6J-N_TBVpZb9iVydg0U0syt","timestamp":1730224757171}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
